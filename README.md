# QueryHub â€“ AI Agent Chat App with RAG + Buffer Memory

QueryHub is a multi-turn AI conversational web app using Retrieval-Augmented Generation (RAG), custom LangChain agents, and vector search. Admins can upload documents (PDF, DOCX, TXT), and users can query them through a smart AI chatbot powered by OpenAI and Pinecone.

Built with:  
- ğŸ§  LangChain Agents + Retriever Tool  
- ğŸ“¦ Pinecone for vector storage (embedding dim: 1536)  
- ğŸ’¬ OpenAI API (LLM + Embeddings)  
- ğŸ§  Redis for buffer memory  
- ğŸ—‚ MongoDB for chat storage  
- ğŸ§‘â€ğŸ’» React + Express.js

---

## âœ¨ Features

- Admin Dashboard: Upload and manage documents  
- User Dashboard: Chat with AI assistant on uploaded docs  
- Multi-turn memory using Redis buffer memory  
- MongoDB chat storage (state preserved on page refresh)  
- RAG + Agent-based conversational responses  
- JWT-based authentication (Admin & User roles)  
- File support: PDF, DOC/DOCX, TXT

---

## ğŸš€ Running Locally

### 1. Clone the repo
git clone https://github.com/yourusername/queryhub.git
cd queryhub

2. Setup Backend
cd backend
npm install

ğŸ”‘ Create a .env file inside /backend:PORT=5000
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_index_name
MONGODB_URI=your_mongodb_uri
REDIS_URL=redis://localhost:6379
JWT_SECRET=your_jwt_secret
NODE_ENV=development


3. Start Redis Server
Make sure Redis is installed and running locally.
On macOS/Linux:redis-server
On Windows:
Install Redis for Windows from: https://redis.io/docs/latest/operate/oss_and_stack/install/archive/install-redis/install-redis-on-windows/

4. Setup Frontend
cd ../frontend
npm install
npm start


ğŸ“Œ 4. How It Works (Architecture Summary)
## ğŸ§  How It Works

1. Admin uploads files â†’ Stored â†’ Parsed â†’ Chunked â†’ Embedded using `text-embedding-3-small` (OpenAI) â†’ Stored in Pinecone
2. User asks a question â†’ Chat history fetched from MongoDB + Redis â†’ LangChain Agent uses retriever + tools â†’ Query Pinecone â†’ Fetch context
3. Agent constructs prompt with retrieved docs + memory â†’ Sends to OpenAI LLM (GPT-4 / GPT-3.5) â†’ Returns response
4. Multi-turn memory is stored in RedisBufferMemory (custom retriever)
5. All chats stored in MongoDB â†’ Shown on page refresh


ğŸ” 5. API Keys Required
## ğŸ” API Keys Required

- ğŸ”‘ [OpenAI API Key](https://platform.openai.com/account/api-keys)
- ğŸ“¦ [Pinecone API Key](https://app.pinecone.io/)
- ğŸƒ MongoDB URI from [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)
- âš¡ Redis (local installation for development)

Make sure to create a Pinecone index with:
- Embedding model: `text-embedding-3-small`
- Dimensions: `1536`
