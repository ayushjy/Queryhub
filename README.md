# ğŸš€ QueryHub â€“ AI Agent Chat App with RAG + Retriever Tool + Buffer Memory

**QueryHub** is a multi-turn AI conversational web app powered by **Retrieval-Augmented Generation (RAG)**, custom **LangChain agents**, and **vector search**. Admins can upload documents (PDF, DOCX, TXT), and users can query them via a smart AI agent chatbot.

---

## ğŸ› ï¸ Built With

- ğŸ§  LangChain Agents + Retriever Tool  
- ğŸ“¦ Pinecone for vector storage (embedding dim: `1536`)  
- ğŸ’¬ OpenAI API (LLM + Embeddings)  
- ğŸ§  Redis for buffer memory  
- ğŸ—‚ MongoDB for persistent chat storage  
- âš›ï¸ React (Frontend) + Express.js (Backend)

---

## âœ¨ Features

- ğŸ” JWT-based authentication (Admin & User roles)  
- ğŸ“ Admin Dashboard: Upload and manage documents  
- ğŸ‘¤ User Dashboard: Chat with AI assistant  
- ğŸ”„ Multi-turn memory using Redis Buffer Memory  
- ğŸ’¾ Persistent chat history stored in MongoDB  
- ğŸ” Agent-based RAG conversational responses  
- ğŸ“‘ File support: PDF, DOC/DOCX, TXT

---

## âš™ï¸ Local Setup Instructions

### 1ï¸âƒ£ Clone the Repository  

git clone https://github.com/ayushjy/Queryhub.git  
cd Queryhub

2ï¸âƒ£ Backend Setup  
cd backend  
npm install  

Create a .env file inside /backend with the following:  
PORT=5000  
OPENAI_API_KEY=your_openai_api_key  
PINECONE_API_KEY=your_pinecone_api_key  
PINECONE_INDEX_NAME=your_index_name  
MONGODB_URI=your_mongodb_uri  
REDIS_URL=redis://localhost:6379  
JWT_SECRET=your_jwt_secret  
NODE_ENV=development  

3ï¸âƒ£ Start Redis Server  
Make sure Redis is installed and running locally.

macOS/Linux:redis-server  
Windows: https://redis.io/docs/latest/operate/oss_and_stack/install/archive/install-redis/install-redis-on-windows/

4ï¸âƒ£ Frontend Setup  
cd ../frontend  
npm install  
npm start  

ğŸ§  How It Works
Admin Uploads File
â†’ Stored â†’ Parsed â†’ Chunked â†’ Embedded via text-embedding-3-small (OpenAI) â†’ Stored in Pinecone.

User Asks Question
â†’ Chat history pulled from MongoDB + Redis
â†’ LangChain Agent uses retriever + tools
â†’ Queries Pinecone â†’ Retrieves relevant context.

LLM Response
â†’ Agent constructs prompt using retrieved docs + memory + user input
â†’ Sends to OpenAI (GPT-4 / GPT-3.5)
â†’ Returns AI response.

Memory
â†’ Multi-turn conversation stored via RedisBufferMemory.

Persistence
â†’ Chat history saved in MongoDB
â†’ Shown again on page refresh.

## ğŸ” API Keys Required

- ğŸ”‘ [OpenAI API Key](https://platform.openai.com/account/api-keys)
- ğŸ“¦ [Pinecone API Key](https://app.pinecone.io/)
- ğŸƒ MongoDB URI from [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)
- âš¡ Redis (local installation for development)

Make sure to create a Pinecone index with:
- Embedding model: `text-embedding-3-small`
- Dimensions: `1536`

ğŸ§‘â€ğŸ’» Author  
Made with â¤ï¸ by Ayush Jyoti
